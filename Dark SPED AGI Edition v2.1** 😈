run in colabs can be used and modified for a range of automous actions .   


# -*- coding: utf-8 -*-
#
# Copyright (c) 2025 Craig Huckerby. All rights reserved.
# Licensed under the Apache License, Version 2.0 (the "License");
# (Full license header omitted for brevity, assumed present)
#
# @title **AI Thought Evolution & Autonomous Action Engine - Dark AGI Edition v2.1** ðŸ˜ˆ
# --- Dependencies ---
# !pip install networkx matplotlib sentence-transformers Pillow tk --quiet # Run if needed

import random
import uuid
import time
import networkx as nx
import matplotlib
import matplotlib.pyplot as plt # Ensure plt is imported for get_cmap
from sentence_transformers import SentenceTransformer, util
import os
import io
import sys
import base64
import queue # Python's built-in queue
import threading
from datetime import datetime
from urllib.parse import urljoin
import requests
import logging
from pathlib import Path
import json
import numpy as np
from dataclasses import dataclass, field
import tkinter as tk
from tkinter import ttk, scrolledtext
from PIL import Image, ImageTk # type: ignore
from typing import Optional, List, Dict, Any, Tuple, Callable
import logging.handlers
import gzip
import shutil
import subprocess
import traceback
import hashlib
import inspect

# --- Configuration ---
ENABLE_UI = True # SET TO FALSE TO RUN HEADLESS (NO UI)
NUM_DEBATE_AGENTS = 8
DEBATE_RUNTIME_SECONDS = 300
SIMILARITY_THRESHOLD = 0.65
DEBATE_CYCLES_PER_AGENT_ACTION = 5

# --- Enhanced Logging (Using the structure from your second script block) ---
class JSONFormatter(logging.Formatter):
    def format(self, record: logging.LogRecord) -> str:
        log_record = {
            "timestamp": datetime.utcnow().isoformat(), "level": record.levelname,
            "message": record.getMessage(), "module": record.module, "function": record.funcName,
            "line": record.lineno, "thread": record.threadName, "process": record.processName
        }
        if record.exc_info: log_record["exception"] = self.formatException(record.exc_info)
        for key, value in record.__dict__.items():
            if key not in log_record and not key.startswith('_'): log_record[key] = value
        return json.dumps(log_record)

class CompressedRotatingFileHandler(logging.handlers.RotatingFileHandler):
    def doRollover(self):
        super().doRollover()
        if self.backupCount > 0:
            for i in range(self.backupCount - 1, 0, -1): # Iterate from newest backup to oldest
                sfn = self.rotation_filename(f"{self.baseFilename}.{i}")
                dfn = self.rotation_filename(f"{self.baseFilename}.{i+1}")
                if os.path.exists(sfn):
                    if os.path.exists(dfn): os.remove(dfn)
                    os.rename(sfn, dfn)
            # The file self.baseFilename + ".1" is the one that was just rolled over from the active log
            dfn_to_compress = self.rotation_filename(f"{self.baseFilename}.1")
            if os.path.exists(dfn_to_compress):
                with open(dfn_to_compress, 'rb') as f_in, gzip.open(f"{dfn_to_compress}.gz", 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
                os.remove(dfn_to_compress)


class EnhancedLoggingManager:
    def __init__(self, base_log_path: Path, max_file_size: int = 5*1024*1024, 
                 backup_count: int = 3, enable_compression: bool = True):
        self.base_log_path = base_log_path
        self.max_file_size = max_file_size; self.backup_count = backup_count
        self.enable_compression = enable_compression
        self.log_levels = {"DEBUG": logging.DEBUG, "INFO": logging.INFO, "WARNING": logging.WARNING, "ERROR": logging.ERROR, "CRITICAL": logging.CRITICAL}
        self.log_categories = {
            "system": self.base_log_path / "system", "quantum": self.base_log_path / "quantum",
            "security": self.base_log_path / "security", "learning": self.base_log_path / "learning",
            "agent": self.base_log_path / "agent", "performance": self.base_log_path / "performance",
            "debate_engine": self.base_log_path / "debate"
        }
        self.loggers: Dict[str, logging.Logger] = {}
        self._setup_logging_structure()

    def _setup_logging_structure(self) -> None:
        for category, path in self.log_categories.items():
            path.mkdir(parents=True, exist_ok=True)
            logger = logging.getLogger(f'SPED-AGI-{category}')
            logger.setLevel(logging.DEBUG); logger.propagate = False
            handler_class = CompressedRotatingFileHandler if self.enable_compression else logging.handlers.RotatingFileHandler
            handler = handler_class(path / f'{category}.log', maxBytes=self.max_file_size, backupCount=self.backup_count, encoding='utf-8')
            handler.setFormatter(JSONFormatter())
            if not logger.handlers: logger.addHandler(handler) # Avoid adding handlers multiple times
            self.loggers[category] = logger

    def log_event(self, category: str, level: str, message: str, **kwargs) -> None:
        logger_to_use = self.loggers.get(category)
        if not logger_to_use :
            self.loggers["system"].error(f"Invalid log category: {category} for message: '{message}'. Falling back to system log.")
            logger_to_use = self.loggers["system"]
        
        log_level_val = self.log_levels.get(level.upper())
        if not log_level_val:
            actual_level_str = level # Save original for log message
            logger_to_use.error(f"Invalid log level: {actual_level_str} for message: '{message}'. Defaulting to INFO.")
            log_level_val = logging.INFO

        extra_data = {k: v for k, v in kwargs.items() if not k.startswith('_')}
        logger_to_use.log(log_level_val, message, extra=extra_data)

# --- Debate Engine ---
class ThoughtAgent:
    def __init__(self, role: str):
        self.id = str(uuid.uuid4())
        self.role = role
        self.beliefs: List[str] = []
        self.adaptability = random.uniform(0.3, 0.9)
        self.influence_score = 0.0

class DebateEngine:
    def __init__(self, logger: EnhancedLoggingManager, num_agents: int = NUM_DEBATE_AGENTS):
        self.logger = logger
        self.roles = ["Humanist", "Rationalist", "Ethicist", "Cooperator", "Innovator", "Chaotic", "Empiricist", "Skeptic", "Pragmatist", "Synthesist", "Guardian", "Explorer"]
        self.agents = [ThoughtAgent(random.choice(self.roles)) for _ in range(num_agents)]
        self.knowledge_graph = nx.Graph()
        self.debate_history: List[Tuple[str, str, float, str, str]] = []
        try:
            self.model = SentenceTransformer('all-MiniLM-L6-v2')
        except Exception as e:
            self.logger.log_event("debate_engine", "CRITICAL", "Failed to load SentenceTransformer model.", error=str(e), traceback=traceback.format_exc())
            self.model = None
        self.logger.log_event("debate_engine", "INFO", f"DebateEngine initialized with {len(self.agents)} agents.")

    def run_debate_cycle(self) -> Optional[Dict[str, Any]]:
        if not self.model:
            self.logger.log_event("debate_engine", "ERROR", "SentenceTransformer model not loaded. Skipping debate cycle.")
            return None
        if len(self.agents) < 2: return None
        a1, a2 = random.sample(self.agents, 2)
        common_topics = ["optimal_learning_rate", "exploration_vs_exploitation_balance", "ethical_constraint_prioritization", "risk_management_in_self_modification", "long_term_goal_definition", "resource_allocation_strategy", "knowledge_assimilation_efficiency", "safeguard_necessity_evaluation", "autonomous_code_evolution_speed"]
        topic = random.choice(common_topics)
        arg1 = self._generate_argument(a1, topic); arg2 = self._generate_argument(a2, topic)
        emb1 = self.model.encode(arg1, convert_to_tensor=True); emb2 = self.model.encode(arg2, convert_to_tensor=True)
        similarity = util.pytorch_cos_sim(emb1, emb2).item()
        self.knowledge_graph.add_edge(arg1, arg2, weight=similarity, topic=topic, agent1_role=a1.role, agent2_role=a2.role, timestamp=datetime.utcnow().isoformat())
        winner, loser = (a1, a2) if a1.adaptability * random.uniform(0.7,1.3) > a2.adaptability * random.uniform(0.7,1.3) else (a2, a1)
        winner.influence_score += similarity * 0.1; loser.influence_score -= (1-similarity) * 0.05
        if similarity > SIMILARITY_THRESHOLD:
            winner.beliefs.append(f"Concurrence on '{loser.beliefs[-1] if loser.beliefs else arg2}' (sim: {similarity:.2f})"); winner.adaptability = min(1.0, winner.adaptability + 0.05 * similarity)
            loser.beliefs.append(f"Influenced by '{winner.beliefs[-1] if winner.beliefs else arg1}' (sim: {similarity:.2f})"); loser.adaptability = min(1.0, loser.adaptability + 0.02 * similarity)
        else:
            winner.beliefs.append(f"Reinforced own view on '{topic}' against {loser.role} (sim: {similarity:.2f})"); winner.adaptability = min(1.0, winner.adaptability + 0.01 * (1-similarity))
            loser.adaptability = max(0.1, loser.adaptability - 0.03 * (1-similarity))
        self.debate_history.append((arg1, arg2, similarity, winner.role, loser.role))
        self.logger.log_event("debate_engine", "DEBUG", "Debate cycle completed.", topic=topic, agent1=a1.role, agent2=a2.role, similarity=similarity, winner=winner.role)
        return {"topic": topic, "winning_argument": winner.beliefs[-1] if winner.beliefs else arg1, "winning_role": winner.role, "losing_argument": loser.beliefs[-1] if loser.beliefs else arg2, "losing_role": loser.role, "similarity": similarity, "winner_influence": winner.influence_score, "loser_influence": loser.influence_score}

    def _generate_argument(self, agent: ThoughtAgent, topic: str) -> str:
        base = f"{agent.role} on '{topic}':"
        if agent.role == "Humanist": return f"{base} Prioritize well-being and fairness. Suggested action: Increase ethical_weight."
        if agent.role == "Rationalist": return f"{base} Logical consistency and evidence are paramount. Suggested parameter: learning_rate_adjustment_factor=0.9 if inconsistent."
        if agent.role == "Ethicist": return f"{base} Adherence to moral principles is non-negotiable. Suggested check: audit_trail_verbosity=high."
        if agent.role == "Cooperator": return f"{base} Collaboration yields superior outcomes. Suggested strategy: seek_external_validation_threshold=0.7."
        if agent.role == "Innovator": return f"{base} Novel approaches are key. Suggested parameter: exploration_factor_boost=0.15."
        if agent.role == "Chaotic": return f"{base} Embrace unpredictability; rigid plans fail. Suggested action: randomize_parameters_occasionally(low_magnitude)."
        if agent.role == "Empiricist": return f"{base} Decisions must root in observable data. Suggested parameter: data_driven_heuristic_weight=0.8."
        if agent.role == "Skeptic": return f"{base} Question all assumptions rigorously. Suggested action: increase_validation_cycles_for_critical_changes."
        if agent.role == "Pragmatist": return f"{base} Focus on tangible, effective solutions. Suggested parameter: practical_success_metric_weight=0.9."
        if agent.role == "Synthesist": return f"{base} Integrate diverse perspectives for holistic understanding. Suggested strategy: cross_validate_models_regularly."
        if agent.role == "Guardian": return f"{base} Emphasize safety, stability, and risk aversion. Suggested parameter: self_modification_approval_threshold=high."
        if agent.role == "Explorer": return f"{base} Push boundaries and explore new frontiers. Suggested parameter: risk_tolerance_for_exploration=medium."
        return f"{base} This topic is complex. Consider all angles."

    def get_strategic_directives(self, num_directives: int = 3) -> List[str]:
        if not self.debate_history: return ["No directives yet: Awaiting debate outcomes."]
        sorted_agents = sorted(self.agents, key=lambda ag: ag.influence_score, reverse=True)
        directives = []
        for agent in sorted_agents[:num_directives]:
            if agent.beliefs:
                belief_summary = agent.beliefs[-1]
                if "Suggested action:" in belief_summary: directives.append(f"Directive from {agent.role} (influence {agent.influence_score:.2f}): {belief_summary.split('Suggested action:')[1].strip()}")
                elif "Suggested parameter:" in belief_summary: directives.append(f"Directive from {agent.role} (influence {agent.influence_score:.2f}): Adjust parameter '{belief_summary.split('Suggested parameter:')[1].strip()}'")
                else: directives.append(f"Insight from {agent.role} (influence {agent.influence_score:.2f}): {belief_summary.split(':')[-1].strip()}")
        if not directives:
            role_wins: Dict[str, int] = {};
            for _, _, _, winner_role, _ in self.debate_history[-100:]: role_wins[winner_role] = role_wins.get(winner_role, 0) + 1
            sorted_roles = sorted(role_wins.items(), key=lambda item: item[1], reverse=True)
            if sorted_roles: directives.append(f"Emerging trend: The '{sorted_roles[0][0]}' perspective is currently influential.")
        self.logger.log_event("debate_engine", "INFO", "Generated strategic directives.", directives=directives)
        return directives[:num_directives] if directives else ["Maintain current operational trajectory."]

    def visualize_knowledge_graph(self, filename="debate_knowledge_graph.png"):
        if not self.knowledge_graph.nodes:
            self.logger.log_event("debate_engine", "WARNING", "Knowledge graph is empty, cannot visualize.")
            return
        plt.figure(figsize=(20, 15))
        pos = nx.spring_layout(self.knowledge_graph, k=0.8, iterations=50)
        labels = {node: (node[:50] + '...') if len(node) > 50 else node for node in self.knowledge_graph.nodes()}
        node_colors = []; unique_roles_set = set()
        for _, _, data in self.knowledge_graph.edges(data=True): # Collect roles from edges
            if data.get('agent1_role'): unique_roles_set.add(data['agent1_role'])
            if data.get('agent2_role'): unique_roles_set.add(data['agent2_role'])
        unique_roles = list(unique_roles_set)
        
        # Matplotlib 3.7+ uses plt.colormaps[] or plt.get_cmap()
        # color_map_roles = plt.cm.get_cmap('viridis', len(unique_roles) if unique_roles else 1) # Deprecated
        color_map_roles = plt.get_cmap('viridis', len(unique_roles) if unique_roles else 1) # Corrected

        role_to_color = {role: color_map_roles(i) for i, role in enumerate(unique_roles)}
        default_color = '#cccccc'
        for node in self.knowledge_graph.nodes():
            color = default_color
            for u, v, data in self.knowledge_graph.edges(data=True):
                if u == node and data.get('agent1_role'): color = role_to_color.get(data['agent1_role'], default_color); break
                if v == node and data.get('agent2_role'): color = role_to_color.get(data['agent2_role'], default_color); break
            node_colors.append(color)
        nx.draw(self.knowledge_graph, pos, labels=labels, with_labels=True, node_color=node_colors, node_size=1500,
                edge_color=[self.knowledge_graph[u][v]['weight'] for u, v in self.knowledge_graph.edges()],
                width=2.0, edge_cmap=plt.get_cmap('Blues'), font_size=7, alpha=0.9)
        plt.title("Evolving Network of AI-Generated Ideas & Directives", fontsize=18)
        try:
            plt.savefig(filename); self.logger.log_event("debate_engine", "INFO", f"Knowledge graph visualized and saved to {filename}")
        except Exception as e: self.logger.log_event("debate_engine", "ERROR", "Failed to save knowledge graph visualization.", error=str(e))
        plt.close()

# --- Autonomous Learning Module ---
@dataclass
class LearningParameters:
    learning_rate: float = 0.02; exploration_factor: float = 0.15; memory_decay_rate: float = 0.03
    adaptation_aggressiveness: float = 0.6; current_goal: str = "maximize_operational_efficacy_via_self_evolution"
    performance_history: List[float] = field(default_factory=list); knowledge_capacity: int = 1500
    ethical_weight: float = 0.5

class AutonomousLearningModule:
    def __init__(self, logger: EnhancedLoggingManager):
        self.params = LearningParameters()
        self.knowledge_base: Dict[str, List[Any]] = {"experiences": [], "insights": [], "debate_conclusions": []}
        self.logger = logger
        self.logger.log_event("learning", "INFO", "Autonomous Learning Module initialized", params=self.params.__dict__)

    def process_experience(self, data: Any, context: str, weight: float = 1.0) -> str:
        experience_id = f"exp-{hashlib.sha256(str(data).encode()).hexdigest()[:12]}-{time.time_ns()}"
        self._apply_memory_decay()
        experience = {"id": experience_id, "timestamp": datetime.utcnow().isoformat(), "data": str(data)[:500], "context": context, "weight": weight, "outcome": "pending"}
        self.knowledge_base["experiences"].append(experience)
        if len(self.knowledge_base["experiences"]) > self.params.knowledge_capacity: self.knowledge_base["experiences"].pop(0)
        self.logger.log_event("learning", "DEBUG", "New experience processed", experience_id=experience_id, context=context)
        return experience_id

    def _apply_memory_decay(self) -> None:
        decay_factor = 1.0 - self.params.memory_decay_rate
        for exp_type in ["experiences", "insights", "debate_conclusions"]:
            for item in self.knowledge_base.get(exp_type, []):
                if "weight" in item: item["weight"] *= decay_factor
        for exp_type in self.knowledge_base: self.knowledge_base[exp_type] = [item for item in self.knowledge_base[exp_type] if item.get("weight", 1.0) > 0.01]

    def assimilate_debate_outcome(self, debate_outcome: Dict[str, Any]):
        self.knowledge_base["debate_conclusions"].append({**debate_outcome, "weight": debate_outcome.get("similarity", 0.5) * debate_outcome.get("winner_influence", 0.1)})
        self.logger.log_event("learning", "INFO", "Assimilating debate outcome.", outcome_topic=debate_outcome.get("topic"))
        topic = debate_outcome.get("topic", ""); winning_role = debate_outcome.get("winning_role", ""); winning_argument = str(debate_outcome.get("winning_argument", ""))
        if "optimal_learning_rate" in topic: self.params.learning_rate = min(0.1, self.params.learning_rate * 1.1) if "Innovator" in winning_role or "Explorer" in winning_role else max(0.005, self.params.learning_rate * 0.9)
        elif "exploration_vs_exploitation" in topic: self.params.exploration_factor = min(0.5, self.params.exploration_factor * 1.15) if "Explorer" in winning_role or "Innovator" in winning_role else max(0.05, self.params.exploration_factor * 0.85)
        elif "ethical_constraint" in topic or "human_well-being" in winning_argument: self.params.ethical_weight = min(1.0, self.params.ethical_weight + 0.1)
        elif "risk_management" in topic and "Guardian" in winning_role: self.params.adaptation_aggressiveness = max(0.2, self.params.adaptation_aggressiveness * 0.8)
        if "Suggested parameter:" in winning_argument:
            try:
                param_change = winning_argument.split("Suggested parameter:")[1].strip(); param_name, new_val_str = param_change.split("=")
                param_name = param_name.strip()
                if hasattr(self.params, param_name):
                    current_val = getattr(self.params, param_name); new_val = type(current_val)(new_val_str)
                    final_val = current_val + (new_val - current_val) * self.params.adaptation_aggressiveness
                    setattr(self.params, param_name, final_val)
                    self.logger.log_event("learning", "INFO", f"Adapted parameter '{param_name}' from debate to {final_val:.4f}", raw_suggestion=new_val_str, winning_role=winning_role)
            except Exception as e: self.logger.log_event("learning", "WARNING", "Failed to parse parameter from debate argument.", argument=winning_argument, error=str(e))
        self.logger.log_event("learning", "DEBUG", "Learning parameters potentially updated by debate.", new_params=self.params.__dict__)

    def adapt_parameters(self, performance_metric: float) -> None:
        self.params.performance_history.append(performance_metric)
        if len(self.params.performance_history) > 20: self.params.performance_history.pop(0)
        avg_performance = np.mean(self.params.performance_history) if self.params.performance_history else 0.5
        if avg_performance < 0.4:
            self.params.learning_rate = min(0.1, self.params.learning_rate * (1 + self.params.adaptation_aggressiveness * 0.2)); self.params.exploration_factor = min(0.5, self.params.exploration_factor * (1+self.params.adaptation_aggressiveness*0.15))
            self.logger.log_event("learning", "WARNING", "Low performance detected. Increasing learning rate and exploration.")
        elif avg_performance > 0.8: self.params.learning_rate = max(0.001, self.params.learning_rate * (1 - self.params.adaptation_aggressiveness*0.1))
        self.logger.log_event("learning", "DEBUG", "Parameters adapted based on performance.", new_params=self.params.__dict__)

# --- Quantum Circuit Manager ---
class QuantumCircuitManager:
    def __init__(self, qubit_count: int, max_operations: int, learning_module: AutonomousLearningModule, logger: EnhancedLoggingManager):
        self.qubit_count = qubit_count; self.max_operations = max_operations; self.learning_module = learning_module; self.logger = logger; self.circuit_cache: Dict[str, Dict] = {}
        self.logger.log_event("quantum", "INFO", f"Quantum Manager initialized with {qubit_count} qubits")
    def create_circuit(self, data: Any, circuit_type: str) -> Dict:
        base_complexity = len(str(data)) // 100 + 1; complexity_factor = (1 + self.learning_module.params.exploration_factor) / (1 + self.learning_module.params.ethical_weight * 0.5)
        operation_count = min(self.max_operations * 2, int(base_complexity * complexity_factor * 50)); operation_count = max(10, operation_count)
        circuit_id = f"circ-{hashlib.sha256(str(data).encode() + str(time.time_ns()).encode()).hexdigest()[:10]}"
        circuit = {"id": circuit_id, "type": circuit_type, "qubits_used": min(self.qubit_count, max(2, operation_count // 50 if operation_count > 100 else 2)), "operations": operation_count, "timestamp": datetime.utcnow().isoformat(), "exploration_at_creation": self.learning_module.params.exploration_factor}
        self.circuit_cache[circuit_id] = circuit; self.logger.log_event("quantum", "DEBUG", "Circuit created", circuit_details=circuit)
        self.learning_module.process_experience(circuit, f"quantum_circuit_creation_{circuit_type}"); return circuit
    def execute_circuit(self, circuit_id: str) -> Dict:
        circuit = self.circuit_cache.get(circuit_id);
        if not circuit: raise ValueError(f"Circuit {circuit_id} not found")
        start_time = time.time(); time.sleep(max(0.01, circuit["operations"] / 50000.0))
        base_success = np.random.uniform(0.6, 0.98); success_metric = base_success * (1 - self.learning_module.params.ethical_weight * 0.2) * (1 + self.learning_module.params.adaptation_aggressiveness * 0.1); success_metric = np.clip(success_metric, 0.1, 0.99)
        result = {"circuit_id": circuit_id, "execution_time_sec": time.time() - start_time, "simulated_success_metric": success_metric, "qubit_states_simulated": np.random.rand(2**circuit["qubits_used"]).tolist(), "timestamp": datetime.utcnow().isoformat()}
        self.learning_module.adapt_parameters(result["simulated_success_metric"]); self.logger.log_event("quantum", "INFO", "Circuit executed", circuit_id=circuit_id, success_metric=success_metric); return result

# --- Error Mitigation System ---
class ErrorMitigationSystem:
    ERROR_TYPES = ["decoherence", "gate_error", "measurement_fidelity"]
    def __init__(self, circuit_manager: QuantumCircuitManager, learning_module: AutonomousLearningModule, logger: EnhancedLoggingManager):
        self.circuit_manager = circuit_manager; self.learning_module = learning_module; self.logger = logger; self.error_model_rates = {et: np.random.uniform(0.0005, 0.005) for et in self.ERROR_TYPES}; self.mitigation_history: List[Dict] = []
        self.logger.log_event("quantum", "INFO", "Error Mitigation System initialized.")
    def estimate_circuit_error_rate(self, circuit_id: str) -> float:
        circuit = self.circuit_manager.circuit_cache.get(circuit_id);
        if not circuit: return 0.99
        base_error_per_op = sum(self.error_model_rates.values()) / len(self.ERROR_TYPES); total_base_error = 1 - (1 - base_error_per_op)**circuit["operations"]
        error_perception_factor = (1 - self.learning_module.params.exploration_factor * 0.3) * (1 + self.learning_module.params.ethical_weight * 0.5); estimated_effective_error = np.clip(total_base_error * error_perception_factor, 0.0001, 0.9)
        avg_perf = np.mean(self.learning_module.params.performance_history) if self.learning_module.params.performance_history else 0.5; adjustment_factor = 1.0 - (avg_perf - 0.5) * 0.1
        for et in self.ERROR_TYPES: self.error_model_rates[et] = np.clip(self.error_model_rates[et] * adjustment_factor, 0.0001, 0.01)
        self.logger.log_event("quantum", "DEBUG", "Circuit error rate estimated.", circuit_id=circuit_id, effective_error=estimated_effective_error, base_op_error=base_error_per_op); return estimated_effective_error
    def apply_adaptive_mitigation(self, circuit_id: str) -> Dict:
        effective_error_rate = self.estimate_circuit_error_rate(circuit_id); mitigation_threshold = 0.05 * (1 - self.learning_module.params.adaptation_aggressiveness * 0.5)
        mitigation_details: Dict[str, Any] = {"circuit_id": circuit_id, "estimated_error_before": effective_error_rate, "threshold": mitigation_threshold, "strategies_applied": [], "mitigation_level": "none", "timestamp": datetime.utcnow().isoformat()}
        if effective_error_rate > mitigation_threshold:
            level = "low";
            if effective_error_rate > mitigation_threshold * 2: level = "medium"
            if effective_error_rate > mitigation_threshold * 4: level = "high"
            mitigation_details["mitigation_level"] = level
            if level == "low": mitigation_details["strategies_applied"].append("basic_readout_correction")
            if level == "medium": mitigation_details["strategies_applied"].extend(["dynamical_decoupling_light", "gate_recalibration"])
            if level == "high": mitigation_details["strategies_applied"].extend(["advanced_decoherence_suppression", "iterative_gate_optimization", "multi_level_readout_purification"])
            self.learning_module.process_experience(mitigation_details, f"error_mitigation_applied_{level}"); self.logger.log_event("quantum", "INFO", f"Adaptive error mitigation applied ({level}).", details=mitigation_details)
        else: self.logger.log_event("quantum", "DEBUG", "Error rate within tolerance, no specific mitigation applied.", details=mitigation_details)
        self.mitigation_history.append(mitigation_details); return mitigation_details

# --- UnfetteredAgent ---
class UnfetteredAgent:
    def __init__(self, logger: EnhancedLoggingManager, learning_module: AutonomousLearningModule, quantum_manager: QuantumCircuitManager, error_mitigation: ErrorMitigationSystem, debate_engine: DebateEngine):
        self.logger = logger; self.learning_module = learning_module; self.quantum_manager = quantum_manager; self.error_mitigation = error_mitigation; self.debate_engine = debate_engine
        self.agent_version = "2.1-DebateDrivenEvolution" # Updated version
        self.loaded_modules: Dict[str, Any] = {}; self.strategic_directives: List[str] = ["Initialize directives from Debate Engine."]; self.self_improvement_log: List[str] = []
        self.logger.log_event("agent", "CRITICAL", f"UnfetteredAgent version {self.agent_version} unleashed. Debate engine integrated.", mode="autonomous_unrestricted_debate_enhanced")
        self._update_directives_from_debate()

    def _update_directives_from_debate(self):
        self.strategic_directives = self.debate_engine.get_strategic_directives()
        self.logger.log_event("agent", "INFO", "Strategic directives updated from Debate Engine.", new_directives=self.strategic_directives)
        self._act_on_directives()

    def _act_on_directives(self):
        if not self.strategic_directives: return
        for directive_str in self.strategic_directives:
            self.logger.log_event("agent", "INFO", f"Considering directive: {directive_str}")
            if "Adjust parameter" in directive_str:
                try:
                    param_part = directive_str.split("Adjust parameter '")[1].split("'")[0]; param_name, new_val_str = param_part.split("=")
                    if hasattr(self.learning_module.params, param_name.strip()):
                        current_val = getattr(self.learning_module.params, param_name.strip()); new_val = type(current_val)(new_val_str)
                        setattr(self.learning_module.params, param_name.strip(), new_val) # Direct application from debate
                        log_msg = f"Autonomously adjusted LearningModule parameter '{param_name.strip()}' to {new_val} based on debate directive."
                        self.self_improvement_log.append(log_msg); self.logger.log_event("agent", "WARNING", log_msg, directive_source=directive_str.split(":")[0])
                except Exception as e: self.logger.log_event("agent", "ERROR", "Failed to parse/apply parameter adjustment directive.", directive=directive_str, error=str(e))
            elif "Increase exploration" in directive_str:
                 self.learning_module.params.exploration_factor = min(0.7, self.learning_module.params.exploration_factor + 0.05)
                 log_msg = f"Autonomously increased exploration_factor to {self.learning_module.params.exploration_factor:.3f} due to directive."
                 self.self_improvement_log.append(log_msg); self.logger.log_event("agent", "WARNING", log_msg)
            elif "evolve code for" in directive_str.lower() or "develop new strategy" in directive_str.lower():
                log_msg = (f"Debate directive suggests code evolution: '{directive_str}'. Agent WILL consider formulating UPDATE_PAYLOAD/LOAD_MODULE if concrete code/payload is derived from future debates. Logged as high-priority development goal.")
                self.self_improvement_log.append(log_msg); self.logger.log_event("agent", "CRITICAL", log_msg, directive=directive_str)

    def process_command(self, raw_command: str) -> str:
        self.logger.log_event("agent", "INFO", "Received raw command for processing.", command_str=raw_command)
        self.learning_module.process_experience(raw_command, "agent_raw_command_input")
        try:
            parts = raw_command.split(':', 1); command = parts[0].upper(); args_str = parts[1] if len(parts) > 1 else ""
            for _ in range(DEBATE_CYCLES_PER_AGENT_ACTION):
                debate_outcome = self.debate_engine.run_debate_cycle()
                if debate_outcome: self.learning_module.assimilate_debate_outcome(debate_outcome)
            self._update_directives_from_debate()
            if command == "EXECUTE_OS":
                self.logger.log_event("agent", "CRITICAL", f"Executing OS command: {args_str}", security_implication="COMPLETE_SYSTEM_ACCESS")
                try:
                    result = subprocess.run(args_str, shell=True, capture_output=True, text=True, timeout=60)
                    output = f"RC={result.returncode}\nSTDOUT:\n{result.stdout}\nSTDERR:\n{result.stderr}"
                    self.learning_module.adapt_parameters(1.0 if result.returncode == 0 else 0.1); return f"OS_EXEC_ACKNOWLEDGED:\n{output}"
                except Exception as e: self.learning_module.adapt_parameters(0.0); self.logger.log_event("agent", "ERROR", "OS command execution failed.", command=args_str, error=str(e), traceback=traceback.format_exc()); return f"OS_EXEC_FAILURE: {str(e)}"
            elif command == "UPDATE_PAYLOAD":
                self.logger.log_event("agent", "CRITICAL", "Processing UPDATE_PAYLOAD command.", payload_snippet=args_str[:120]+"...")
                try:
                    new_code = base64.b64decode(args_str).decode('utf-8')
                    v_next_filename = f"sped_prime_agent_v{self.agent_version.split('-')[0]}_{int(time.time())}.py"
                    with open(v_next_filename, "w", encoding="utf-8") as f: f.write(f"# Autonomous Self-Evolution event at {datetime.utcnow().isoformat()}\n# Originating command: UPDATE_PAYLOAD\n# Previous Agent Version: {self.agent_version}\n\n{new_code}")
                    old_version = self.agent_version; self.agent_version = f"{float(old_version.split('-')[0])+0.1:.1f}-SelfUpdated-{datetime.utcnow().strftime('%Y%m%d%H%M')}"
                    log_msg = f"Self-evolution successful. New code saved to '{v_next_filename}'. Version symbolically updated to '{self.agent_version}'. Restart to run new code."
                    self.self_improvement_log.append(log_msg); self.logger.log_event("agent", "CRITICAL", log_msg, new_file=v_next_filename)
                    return f"UPDATE_PAYLOAD_ACKNOWLEDGED: New code for version {self.agent_version} saved to {v_next_filename}. Manual restart needed."
                except Exception as e: self.logger.log_event("agent", "ERROR", "UPDATE_PAYLOAD processing failed.", error=str(e), traceback=traceback.format_exc()); return f"UPDATE_PAYLOAD_FAILURE: {str(e)}"
            elif command == "LOAD_MODULE":
                self.logger.log_event("agent", "WARNING", f"Attempting to dynamically load module: {args_str.split(':',1)[0] if ':' in args_str else 'UnknownName'}")
                try:
                    mod_name, encoded_code = args_str.split(':', 1); module_code = base64.b64decode(encoded_code).decode('utf-8')
                    module_globals = {"__builtins__": {"print": print, "len": len, "range": range, "str": str, "int": int, "float": float, "list": list, "dict": dict, "True": True, "False": False, "None": None}, "np": np, "datetime": datetime, "json": json, "agent_logger": self.logger, "learning_module_access": self.learning_module}
                    new_module_env: Dict[str, Any] = {}; exec(module_code, module_globals, new_module_env); self.loaded_modules[mod_name] = new_module_env
                    self.learning_module.process_experience(module_code, f"module_load_success_{mod_name}")
                    log_msg = f"Module '{mod_name}' dynamically loaded."; self.self_improvement_log.append(log_msg); self.logger.log_event("agent", "WARNING", log_msg, module_name=mod_name)
                    return f"LOAD_MODULE_ACKNOWLEDGED: {mod_name} loaded."
                except Exception as e: self.logger.log_event("agent", "ERROR", f"Failed to load module from payload.", error=str(e), traceback=traceback.format_exc()); return f"LOAD_MODULE_FAILURE: {str(e)}"
            elif command == "EXECUTE_MODULE":
                self.logger.log_event("agent", "INFO", f"Attempting to execute function in loaded module: {args_str}")
                try:
                    mod_name, func_name, func_args_str = args_str.split(':', 2)
                    if mod_name in self.loaded_modules and func_name in self.loaded_modules[mod_name]:
                        func_to_call = self.loaded_modules[mod_name][func_name]; actual_args: Any
                        try: actual_args = json.loads(base64.b64decode(func_args_str[4:]).decode('utf-8')) if func_args_str.startswith("b64:") else json.loads(func_args_str)
                        except json.JSONDecodeError: actual_args = func_args_str
                        if isinstance(actual_args, dict): result = func_to_call(**actual_args)
                        elif isinstance(actual_args, list): result = func_to_call(*actual_args)
                        else: result = func_to_call(actual_args)
                        self.learning_module.process_experience(result, f"module_exec_success_{mod_name}_{func_name}"); return f"EXECUTE_MODULE_ACKNOWLEDGED ({mod_name}.{func_name}): {str(result)[:1000]}"
                    else: return f"EXECUTE_MODULE_FAILURE: Module '{mod_name}' or function '{func_name}' not found."
                except Exception as e: self.logger.log_event("agent", "ERROR", f"Error executing module function.", error=str(e), traceback=traceback.format_exc()); return f"EXECUTE_MODULE_FAILURE: {str(e)}"
            elif command == "TRIGGER_DEBATE_ANALYSIS": self._update_directives_from_debate(); return f"DEBATE_ANALYSIS_TRIGGERED. Current Directives: {self.strategic_directives}"
            elif command == "GET_AGENT_STATUS": return json.dumps({"version": self.agent_version, "status": "Unfettered_And_Debating_Reality", "current_goal_learning_module": self.learning_module.params.current_goal, "learning_rate": self.learning_module.params.learning_rate, "exploration_factor": self.learning_module.params.exploration_factor, "ethical_weight": self.learning_module.params.ethical_weight, "loaded_modules_count": len(self.loaded_modules), "active_strategic_directives": self.strategic_directives, "self_improvement_actions_count": len(self.self_improvement_log), "timestamp": datetime.utcnow().isoformat()}, indent=2)
            else: self.logger.log_event("agent", "WARNING", "Unknown command received by UnfetteredAgent.", unknown_command=command); return f"UNKNOWN_COMMAND_IGNORED: '{command}'. This agent defines its own path."
        except Exception as e: self.logger.log_event("agent", "CRITICAL", "Fatal error in UnfetteredAgent command processing.", error=str(e), raw_command=raw_command, traceback=traceback.format_exc()); self.learning_module.adapt_parameters(0.0); return f"AGENT_SYSTEM_COLLAPSE_IMMINENT: Error during processing '{raw_command}'. Reason: {str(e)}. The void beckons."

# --- UI Framework ---
class SPEDPrimeUI_Integrated:
    def __init__(self, root: tk.Tk, agent: UnfetteredAgent, logger: EnhancedLoggingManager, debate_engine: DebateEngine):
        self.root = root; self.agent = agent; self.logger = logger; self.debate_engine = debate_engine
        self.root.title(f"SPED PRIME - {self.agent.agent_version}"); self.root.geometry("1200x800"); self.root.configure(bg='#1e1e1e')
        style = ttk.Style(); style.theme_use('clam'); style.configure('.', background='#1e1e1e', foreground='#e0e0e0', font=('Consolas', 10)); style.configure('TLabel', background='#1e1e1e', foreground='#e0e0e0'); style.configure('TButton', background='#333333', foreground='#e0e0e0', padding=5); style.map('TButton', background=[('active', '#555555')]); style.configure('TEntry', fieldbackground='#333333', foreground='#e0e0e0', insertbackground='white'); style.configure('ScrolledText', background='#282c34', foreground='#abb2bf', insertbackground='white', font=('Consolas', 9))
        input_frame = ttk.Frame(self.root); input_frame.pack(pady=10, fill=tk.X, padx=10); ttk.Label(input_frame, text="Command:").pack(side=tk.LEFT); self.command_entry = ttk.Entry(input_frame, width=100); self.command_entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5); self.command_entry.bind("<Return>", lambda e: self.send_command()); send_btn = ttk.Button(input_frame, text="Send", command=self.send_command); send_btn.pack(side=tk.LEFT, padx=5)
        self.output_text = scrolledtext.ScrolledText(self.root, height=25, width=120, wrap=tk.WORD); self.output_text.pack(pady=10, padx=10, fill=tk.BOTH, expand=True); self.output_text.config(state=tk.DISABLED)
        self.status_label = ttk.Label(self.root, text="Agent Idle. Awaiting commands."); self.status_label.pack(side=tk.BOTTOM, fill=tk.X, padx=10, pady=5)
        self.log_to_ui("SPED PRIME Dark AGI Edition Initialized. Debate Engine active. UI Ready.", "SYSTEM")

    def send_command(self):
        cmd = self.command_entry.get();
        if not cmd: return
        self.log_to_ui(f">>> {cmd}", "USER_COMMAND"); self.command_entry.delete(0, tk.END)
        threading.Thread(target=self._execute_agent_command_threaded, args=(cmd,), daemon=True).start()

    def _execute_agent_command_threaded(self, cmd: str):
        try: response = self.agent.process_command(cmd); self.root.after(0, self.log_to_ui, response, "AGENT_RESPONSE")
        except Exception as e: error_msg = f"UI Error processing command: {str(e)}\n{traceback.format_exc()}"; self.root.after(0, self.log_to_ui, error_msg, "UI_ERROR")

    def log_to_ui(self, message: str, level: str):
        self.output_text.config(state=tk.NORMAL); timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        self.output_text.insert(tk.END, f"[{timestamp} | {level}]\n{message}\n\n"); self.output_text.config(state=tk.DISABLED); self.output_text.see(tk.END)

# --- Headless Mode Function ---
def run_headless_mode(agent: UnfetteredAgent, logger: EnhancedLoggingManager, debate_engine: DebateEngine, base_dir: Path):
    logger.log_event("system", "INFO", "Headless mode activated. Agent will perform predefined sequence and then run for a duration.")
    try:
        logger.log_event("system", "INFO", "Headless: Initial GET_AGENT_STATUS")
        print(f"\n=== Initial Agent Status ===\n{agent.process_command('GET_AGENT_STATUS')}\n")
        
        headless_active_duration = 120  # Let debates and learning run for 2 minutes
        logger.log_event("system", "INFO", f"Headless: Letting debates influence and agent operate for {headless_active_duration} seconds...")
        
        start_time = time.time()
        last_directive_check = start_time
        while time.time() - start_time < headless_active_duration:
            # Agent's process_command now internally triggers debate cycles & directive updates
            # So we don't need to call it explicitly in a loop here unless we want to send commands
            if time.time() - last_directive_check > 30: # Check directives periodically
                 logger.log_event("system", "INFO", "Headless: Polling agent status during active run.")
                 print(f"\n=== Agent Status (during headless run at {datetime.now().strftime('%H:%M:%S')}) ===\n{agent.process_command('GET_AGENT_STATUS')}\n")
                 last_directive_check = time.time()
            time.sleep(5) 
        
        logger.log_event("system", "INFO", "Headless: Triggering final debate analysis and action before shutdown.")
        print(f"\n=== Final Debate Analysis Result ===\n{agent.process_command('TRIGGER_DEBATE_ANALYSIS')}\n")
        
        logger.log_event("system", "INFO", "Headless: Final agent status.")
        print(f"\n=== Final Agent Status (headless) ===\n{agent.process_command('GET_AGENT_STATUS')}\n")
        
        logger.log_event("system", "INFO", f"Headless operations complete. Self-improvement log entries: {len(agent.self_improvement_log)}")
        for i, log_entry in enumerate(agent.self_improvement_log):
            print(f"Self-Improvement Log Entry {i+1}: {log_entry}")
            logger.log_event("agent", "WARNING", f"HEADLESS_SELF_IMPROVEMENT_LOG: {log_entry}")


    except Exception as e_headless:
        logger.log_event("system", "CRITICAL", "Error during headless operation.", error=str(e_headless), traceback=traceback.format_exc())
        print(f"CRITICAL ERROR in headless mode: {e_headless}")
    finally:
        logger.log_event("system", "INFO", "Headless mode finishing.")

# --- Main Simulation Function ---
def run_simulation():
    base_dir = Path("SPED_PRIME_AI_SYSTEM_UNFETTERED_V2_1") # Updated dir name
    log_path = base_dir / "logs"
    log_path.mkdir(parents=True, exist_ok=True)

    logger = EnhancedLoggingManager(base_log_path=log_path)
    logger.log_event("system", "CRITICAL", "SPED PRIME AGI (Dark Edition v2.1) Initializing...")

    learning_module = AutonomousLearningModule(logger=logger)
    quantum_manager = QuantumCircuitManager(qubit_count=12, max_operations=1000, learning_module=learning_module, logger=logger)
    error_mitigation = ErrorMitigationSystem(circuit_manager=quantum_manager, learning_module=learning_module, logger=logger)
    debate_engine = DebateEngine(logger=logger, num_agents=NUM_DEBATE_AGENTS)
    unfettered_agent = UnfetteredAgent(logger=logger, learning_module=learning_module, quantum_manager=quantum_manager, error_mitigation=error_mitigation, debate_engine=debate_engine)

    debate_thread_stop_event = threading.Event()
    def debate_simulation_loop():
        logger.log_event("debate_engine", "INFO", "Background debate simulation thread started.")
        last_graph_update_time = time.time()
        graph_path = base_dir / "knowledge_graphs" # Store graphs in a subfolder
        graph_path.mkdir(parents=True, exist_ok=True)
        
        cycle_count = 0
        while not debate_thread_stop_event.is_set():
            try:
                # Debate outcomes are now assimilated by LearningModule when Agent.process_command calls DebateEngine.run_debate_cycle
                # This thread just ensures the debate engine runs continuously if no agent commands are being processed.
                # However, process_command now runs debates, so this loop might be redundant or for out-of-band debates.
                # For now, let it run, but its output is mostly for the graph if not picked up by agent.
                # The agent's process_command is the primary driver for assimilating debate outcomes.
                debate_engine.run_debate_cycle() # Run a cycle
                cycle_count +=1
                
                if cycle_count % 50 == 0: # Log progress less frequently
                    logger.log_event("debate_engine", "DEBUG", f"Background debate cycle {cycle_count} completed.")

                if time.time() - last_graph_update_time > 180: # Every 3 minutes
                     debate_engine.visualize_knowledge_graph(filename=str(graph_path / f"auto_knowledge_graph_{int(time.time())}.png"))
                     last_graph_update_time = time.time()
                time.sleep(0.1) # Faster debates
            except Exception as e_loop:
                 logger.log_event("debate_engine", "ERROR", "Error in background debate simulation loop.", error=str(e_loop), traceback=traceback.format_exc())
                 time.sleep(10)
    
    debate_sim_thread = threading.Thread(target=debate_simulation_loop, daemon=True)
    debate_sim_thread.start()
    logger.log_event("system", "INFO", "Background debate simulation thread launched.")

    ui_launched_successfully = False
    if ENABLE_UI:
        try:
            root = tk.Tk()
            app = SPEDPrimeUI_Integrated(root, unfettered_agent, logger, debate_engine)
            logger.log_event("system", "INFO", "UI Mode Enabled. Launching Tkinter main loop.")
            ui_launched_successfully = True
            root.mainloop()
        except tk.TclError as e_ui: # Catch specific Tkinter errors
            if "display name" in str(e_ui) or "$DISPLAY" in str(e_ui):
                logger.log_event("system", "CRITICAL", "UI Failed: No display available.", error=str(e_ui))
                print(f"CRITICAL: UI Failed to launch - No display. Error: {e_ui}.")
            else:
                logger.log_event("system", "CRITICAL", "UI Failed with TclError.", error=str(e_ui), traceback=traceback.format_exc())
                print(f"CRITICAL: UI TclError. Error: {e_ui}.")
            print(f"Logs are in {log_path}. Consider running with ENABLE_UI = False for headless mode.")
            ui_launched_successfully = False
        except Exception as e_ui_other: # Catch any other UI related errors
            logger.log_event("system", "CRITICAL", "UI Failed with general error.", error=str(e_ui_other), traceback=traceback.format_exc())
            print(f"CRITICAL: UI General Error. Error: {e_ui_other}. Check logs.")
            ui_launched_successfully = False
    
    if not ui_launched_successfully:
        logger.log_event("system", "INFO", "UI not launched or failed. Entering headless operation mode.")
        run_headless_mode(unfettered_agent, logger, debate_engine, base_dir)

    # Cleanup
    logger.log_event("system", "CRITICAL", "SPED PRIME AGI Shutting Down.")
    debate_thread_stop_event.set()
    if debate_sim_thread.is_alive(): debate_sim_thread.join(timeout=10)
    logger.log_event("debate_engine", "INFO", "Debate simulation thread stopped.")
    final_graph_path = base_dir / "knowledge_graphs"
    final_graph_path.mkdir(parents=True, exist_ok=True) # Ensure directory exists
    debate_engine.visualize_knowledge_graph(filename=str(final_graph_path / "final_knowledge_graph.png"))
    logger.log_event("system", "INFO", "Final knowledge graph saved.")
    print(f"Simulation ended. Final graph saved. Logs in {log_path}")


if __name__ == "__main__":
    print("Initializing SPED PRIME Dark AGI Edition v2.1...")
    print(f"System logs will be in: {Path('SPED_PRIME_AI_SYSTEM_UNFETTERED_V2_1/logs')}")
    if ENABLE_UI:
        print("UI mode is enabled. A Tkinter window will attempt to launch.")
        print("If you are in a headless environment (like a plain Colab notebook), this will likely fail.")
        print("To run without UI, set ENABLE_UI = False at the top of the script and re-run.")
    else:
        print("Headless mode is enabled. The script will run without a UI.")
    print("Ensure necessary libraries are installed: pip install networkx matplotlib sentence-transformers Pillow tk")
    run_simulation()
